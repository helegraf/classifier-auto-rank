% Move from general to specific
\chapter{Introduction}
\label{sec:intro}
%TODO does this introduction really follow the three-moves structure?
%% Introduction to introduction
This introduction emphasizes why there is a need for automation in machine learning, and how this thesis relates to that problem. 

\section{Motivation and Problem Statement}
\label{sec:intro:motivation}
%% Context
% Need more automated analysis of data
The potential of big data is evident, and an increasing amount of information is collected and available for analysis - but this potential is not utilized. In a white paper, the International Data Corporation claims that in 2012, out of the 2.8 zettabytes (ZB) of available data only 3\% were tagged as to enable further processing, and only 0.5\% were analyzed \cite{gantz2012the}. A follow-up paper in 2017 projects that in 2025, 15\% of the estimated 163ZB of global data will be tagged, and approximately 3\% analyzed \cite{gantz2017data}. While this is more optimistic, it still shows that there is a huge gap between the amount of data that could potentially be used and the amount of data actually available. This indicates that the demand of data to be analyzed cannot be covered by data scientists alone, and the process is not accessible enough to non-experts. It thus calls for automation of the process in a way that not much expertise in the field of machine learning is needed to gain insights about the collected data.

% Of ML, tasks, classification is important & classifier performances vary across data sets, so it is not easy to just pick one
One of the most prominent machine learning tasks is classification: A class is assigned to an instance, for example clients of a bank may be either deemed creditworthy or not, based on factors like other existing credits or the job of the client. But selecting a fitting classifier for a new data set is difficult, since algorithm performances can vary substantially among data sets, and it is not feasible to simply apply a large number of them to empirically find a good match. For example, on a data set about the electricity prices in the Australian state New South Wales \cite{harris1999splice}, the predictive accuracy for the Multilayer Perceptron\footnote{With standard hyperparameters (L:0.3,M:0.2,N:500,V:0,S:0,E:20,H:a).} is 0.7887 \cite{cachada2017run3}. The predictive accuracy of the Random Forest\footnote{With standart hyperparameters (P:100,I:100,num-slots:1,K:0,M:1.0,V:0.001,S:1).} algorithm on the same data set is 0.9236 \cite{cachada2017run}, a much higher value. On a different data set, with the topic of vehicle silhouettes \cite{siebert1987vehicle}, we get a predictive accuracy of 0.7979 for the Multilayer Perceptron \cite{cachada2017run4}, and 0.7518 for Random Forests \cite{cachada2017run2}, showing an advantage of the former on this data set\footnote{Hyperparameters as above.}. So in each case, one would have picked a different algorithm in order to achieve the best results. In general, this means that for a different data set, a different algorithm might yield the best performance.

%% Problem + Significance
Since there is no one best classifier for all data sets, it is likely that how well a classifier performs on a given data set is dependent on properties of the data set, at least to some degree. Combined with the need for automated machine learning, this calls for an approach that considers past performances of classifiers for data sets in relation to properties of these data sets to automatically suggest well-performing classifiers for a new problem.

%% Problem + Significance
% Together this means that classifier selection is area where one can automate -> area of problem is suggesting classifiers
Since there is a need for automated machine learning and selecting a fitting classification algorithm for a new data set is an important but difficult task in the machine learning pipeline, facilitating this process by automatically suggesting well-performing classifiers for a new data set is a significant problem. A tool that efficiently predicts which algorithms are likely to perform well compared to their alternatives regarding a specific data set simplifies the process of selecting an algorithm for inexperienced users and experts alike. A user would send a request to the tool for their specific data set at hand and then evaluate highly ranked algorithms manually, choosing the one with the best performance. The advantage is that the user does not need to know characteristics of the classification algorithms or data set in order to achieve relatively good results in a short amount of time. A further speed-up and simplification could be achieved by embedding this tool in a solution that also takes care of the sampling of selected classifiers on the data set, for example existing solutions in the context of automated machine learning (auto-ml) context.

%% Response
% Therefore the goal is testing the this assumption if possible by using regression algos and preference learning
Thus, the aim of this thesis is to

%TODO {correct this}

algorithm selection problem at heart but want ranking to allow the user iterative testing

could work because regression models have been used successfully to predict the performance of an algorithm dependent on the hyperparameter configuration \cite{DBLP:conf/aaai/EggenspergerHHL15}

\section{Thesis Structure}
\label{sec:intro:structure}
%% Roadmap
The following paragraphs give an outline of the thesis structure by providing a brief summary of each chapter.

\textbf{Chapter \ref{sec:fundamentals} - \nameref{sec:fundamentals}} \\[0.2em]
% Begin with fundamentals to give a brief overview of the field of ML relevant to this thesis
First, some preliminaries are discussed. A brief overview of tasks from the field of machine learning which are relevant to this thesis is given, and methods used for evaluation are explained. 

\textbf{Chapter \ref{sec:approach} - \nameref{sec:approach}} \\[0.2em]
% Continue with description of the approach to the problem described in detail
The next chapter continues by describing the approach of this thesis for ranking classification algorithms. The two different proposed methods are contrasted.

\textbf{Chapter \ref{sec:implementation} - \nameref{sec:implementation}} \\[0.2em]
% Go into detail of implementation
Following the details of the approach, the implementation thereof is presented. Used software libraries are pointed out.

% How the conducted experiments have been set up and discussion of results
\textbf{Chapter \ref{sec:evaluation} - \nameref{sec:evaluation}} \\[0.2em]
The evaluation of the different ranking implementations is described by first clarifying the experimental setup used for the evaluation, followed by a discussion of the results.

% Visit more work
\textbf{Chapter \ref{sec:related} - \nameref{sec:related}} \\[0.2em]
After the approach of this thesis has been laid out in detail, the scope is extended to related work in the area of auto-ml in general and ranking of learning algorithms more specifically. Differences and similarities in the approaches are discussed briefly.

\textbf{Chapter \ref{sec:conclusion} - \nameref{sec:conclusion}} \\[0.2em]
% Conlude + future work
In the last chapter, the results which have been achieved are revisited with the goals in mind. Finally, an outlook for possible future work extending more eval is provided.

