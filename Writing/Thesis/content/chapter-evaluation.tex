% !TEX root = ../my-thesis.tex
%
\chapter{Evaluation}
\label{sec:evaluation}

\section{Experimental Setup}

% Gathering data sets from OpenML

% Generating base performance data

% Oracle

% Best Algo Performance
Both variants compared against Best Algorithm baseline, which was implemented as a Ranker of type PreferenceRanker itself and evaluated the same way as the other PreferenceRankers. This baseline is computed iteratively by training an oracle on the same data set and then 

% Evaluation Measures used & computed

% How find best version of preference and regression ranker

\section{Results}

% Results of Base Algorithms and full meta features
% - scatter plot dataset -> best preferenceRanker, best regressionRanker, bestAlgorithmbaseline each Kendall

% Results include the 4 evals on all sets, how long predictions took. Meta feature calc times sperately, but may give avg of comp+predict time each time meta feature values table in appendix with mean,min,max stdev

% When removing probing

% When removing expensive meta features

% Results of optimized variants? full / no probing / no expensive

% Insights about classifiers: place best ranking, min, max rank (optional) for each classif?
% TODO replace by large data set
\begin{table}[h]
\centering
	\begin{tabularx}{\textwidth}{X | X}
		%\hline
		Classifier		&	Number of Data Sets Placed First \\	\hline
		Logistic			&	28								\\	\hline	
		Naive Bayes			&	29								\\	\hline	
		IBk		&	23								\\	\hline	
		KStar			&	24								\\	\hline	
		LMT		&	17								\\	\hline	
		VotedPerceptron		&	16								\\	\hline	
		ZeroR		&	14								\\	\hline	
		J48			&	13								\\	\hline	
		NaiveBayesMultinomial			&	6								\\	\hline	
		RandomTree			&	2								\\	\hline	
		SimpleLogistic			&	1								\\	\hline
		DecisionStump			&	1								\\	\hline
		MultilayerPerceptron			&	1								\\	\hline
		RandomForest			&	1								\\	\hline
		DecisionTable			&	1								\\	\hline
		PART			&	1								\\	\hline
		SGD			&	1								\\	\hline
		BayesNet			&	1								\\	\hline
		REPTree			&	1								\\	\hline
		JRip			&	1								\\	\hline
		SMO			&	313								\\	\hline
		OneR			&	448								\\	\hline
																					
	\end{tabularx}
	\label{tab:table1}
	\caption{The ranking }
\end{table}

\pgfplotsset{width=\textwidth}
\begin{tikzpicture}
\begin{axis}
\addplot [mark=*,only marks,mark size=1pt] table [x=ID,y=Loss,col sep=semicolon] {data/InstanceBasedLabelRankingKemenyYoung_metaData_small_allPerformanceValues.csv};
\addplot [mark=*,only marks,mark size=1pt,red] table [x=ID,y=Loss,col sep=semicolon] {data/BestAlgorithmRanker_metaData_small_allPerformanceValues.csv};
\addplot [mark=none,red,samples=2,domain=0:450]{6.48};
\addplot [mark=none,black,samples=2,domain=0:450]{5.44};
\legend{IB Label KY, Best Algorithm}
\end{axis}
\end{tikzpicture}