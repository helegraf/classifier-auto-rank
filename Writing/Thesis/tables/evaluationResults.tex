\begin{landscape}
\begin{table}[h]
\centering
	\resizebox{23,7cm}{!}{%
	\begin{tabularx}{27cm}{>{\hsize=2.8\hsize}X | >{\hsize=.8\hsize\raggedleft\arraybackslash}X | >{\hsize=.8\hsize\raggedleft\arraybackslash}X | >{\hsize=1\hsize\raggedleft\arraybackslash}X  >{\hsize=.8\hsize\raggedleft\arraybackslash}X | >{\hsize=.8\hsize\raggedleft\arraybackslash}X | >{\hsize=.8\hsize\raggedleft\arraybackslash}X | >{\hsize=1\hsize\raggedleft\arraybackslash}X  >{\hsize=.8\hsize\raggedleft\arraybackslash}X| >{\hsize=.8\hsize\raggedleft\arraybackslash}X | >{\hsize=.8\hsize\raggedleft\arraybackslash}X | >{\hsize=1\hsize\raggedleft\arraybackslash}X  >{\hsize=.8\hsize\raggedleft\arraybackslash}X}
		Ranker 				& \multicolumn{4}{>{\hsize=4.0\hsize\centering\arraybackslash}X}{Kendall's Rank Correlation} & \multicolumn{4}{>{\hsize=4.0\hsize\centering\arraybackslash}X}{Loss} & \multicolumn{4}{>{\hsize=4.0\hsize\centering\arraybackslash}X}{BestThreeLoss}\\ \cline{2-13}
							 			& Min	& Max	& Mean			  & $\pm$Stdv  & Min & Max  & Mean			 & $\pm$Stdv   & Min	& Max	 & Mean			  & 	$\pm$Stdv  \\ \hline
		LinearRegression 				& -0.255 & 0.896 & $\bullet$ 0.473 & $\pm$0.221 & 0 & 86.667 & $\bullet$ 3.469 & $\pm$7.244  & 0 & 31.220  & $\bullet$ \textbf{1.267} & $\pm$3.011 \\
		M5P				 				& -0.290 & 0.870 & $\bullet$ 0.470 & $\pm$0.219 & 0 & 82.353 & 3.780	 		 & $\pm$6.535  & 0 & 82.353  & $\bullet$ 1.508 & $\pm$4.757 \\	
		RandomForest		 				& -0.281 & 0.922 & $\bullet$ \textbf{0.495} & $\pm$0.228 & 0 & 60.000 & $\bullet$ \textbf{3.097} & $\pm$5.745  & 0 & 34.634  & $\bullet$ 1.308 & $\pm$3.150 \\	
		REPTree			 				& -0.229 & 0.896 & $\bullet$ 0.412 & $\pm$0.213 & 0 & 82.353 & 4.829	 		 & $\pm$7.948  & 0 & 34.634  & 1.759	 		  & $\pm$3.515 \\	
		InstanceBased 					& -0.429 & 0.870 & $\circ$ 0.221	  & $\pm$0.249 & 0 & 82.353 & $\circ$ 5.401 	 & $\pm$9.440  & 0 & 82.353  & $\circ$ 3.620	  & $\pm$8.540 \\	
		InstanceBased\footnotemark{}		& -0.429 & 0.887 & $\bullet$ 0.340 & $\pm$0.252 & 0 & 98.367 & 5.437 			 & $\pm$10.323 & 0 & 82.353  & 3.294	 		  & $\pm$8.367 \\	
		InstanceBased\footnotemark{}		& -0.429 & 0.870 & $\bullet$ 0.335 & $\pm$0.249 & 0 & 82.353 & $\circ$ 5.382	 & $\pm$9.402  & 0 & 82.353  & $\circ$ 3.511	  & $\pm$8.493 \\	
		PairwiseComparison 				& -0.870 & 0.576	 & $\circ$ 0.014	  & $\pm$0.234 & 0 & 97.822 & $\circ$ 9.762	 & $\pm$13.135 & 0 & 82.353  & $\circ$ 4.001	  & $\pm$8.600 \\	
		BestAlgorithm	 				& -0.351 & 0.758 & 0.296	 		  & $\pm$0.213 & 0 & 82.353 & 4.480 			 & $\pm$9.205  & 0 & 82.353  & 2.440 		  & $\pm$7.625 \\							\hline \hline
		\addtocounter{footnote}{-2}
		LinearRegression 				& -0.532 & 0.835 & $\bullet$ 0.350 & $\pm$0.235 & 0 & 82.353 & 4.921	 		 & $\pm$9.109  & 0 & 82.353 & 2.211	 		& $\pm$6.744 \\
		M5P				 				& -0.290	 & 0.887 & $\bullet$ 0.344 & $\pm$0.219 & 0 & 87.455 & 5.367	 		 & $\pm$9.662  & 0 & 82.353 & 2.060	 		& $\pm$5.466 \\	
		RandomForest		 				& -0.359 & 0.913 & $\bullet$ \textbf{0.439} & $\pm$0.233 & 0 & 82.353 & \textbf{3.538} & $\pm$6.803  & 0 & 40.000 & \textbf{1.587} & $\pm$3.784 \\	
		REPTree			 				& -0.290 & 0.844 & 0.301			  & $\pm$0.215 & 0 & 91.154 & $\circ$ 6.771	 & $\pm$10.710 & 0 & 82.353 & $\circ$ 3.013	& $\pm$7.162 \\	
		InstanceBased 					& -0.429 & 0.870 & $\circ$ 0.221	  & $\pm$0.249 & 0 & 82.353 & $\circ$ 5.401 	 & $\pm$9.429  & 0 & 82.353 & $\circ$ 3.615	& $\pm$8.531 \\	
		InstanceBased\footnotemark{}		& -0.429 & 0.887 & $\bullet$ 0.340 & $\pm$0.252 & 0 & 98.367 & 5.437 			 & $\pm$10.311 & 0 & 82.353 & 3.294	 		& $\pm$8.357 \\	
		InstanceBased\footnotemark{}		& -0.429 & 0.870 & $\bullet$ 0.335 & $\pm$0.249 & 0 & 82.353 & $\circ$ 5.382	 & $\pm$9.391  & 0 & 82.353 & $\circ$ 3.511	& $\pm$8.483 \\	
		PairwiseComparison 				& -0.870 & 0.524	 & $\circ$ 0.013	  & $\pm$0.232 & 0 & 91.667 & $\circ$ 9.486	 & $\pm$13.158 & 0 & 82.353 & $\circ$ 4.096	& $\pm$8.669 \\	
		BestAlgorithm	 				& -0.351 & 0.758 & 0.296	 		  & $\pm$0.213 & 0 & 82.353 & 4.479 			 & $\pm$9.205  & 0 & 82.353 & 2.440 			& $\pm$7.625 \\						
	\end{tabularx}
	}
	\caption{Evaluation results with full meta data (top) and no probing (bottom). The \textbf{best mean value}, $\bullet$ significant advantages, and $\circ$ significant disadvantages are marked as  such.}
	\label{tab:evaluationResults}
\end{table}

\addtocounter{footnote}{-2}
\stepcounter{footnote}\footnotetext{Rankaggregation: Kemeny-Young}
\stepcounter{footnote}\footnotetext{Rankaggregation: Kemeny-Young, base learner KNN with k=$\sqrt{\text{number of instances}}$}
\end{landscape}